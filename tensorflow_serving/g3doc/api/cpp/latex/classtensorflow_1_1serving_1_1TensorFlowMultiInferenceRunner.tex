\hypertarget{classtensorflow_1_1serving_1_1TensorFlowMultiInferenceRunner}{}\doxysection{tensorflow\+::serving\+::Tensor\+Flow\+Multi\+Inference\+Runner Class Reference}
\label{classtensorflow_1_1serving_1_1TensorFlowMultiInferenceRunner}\index{tensorflow::serving::TensorFlowMultiInferenceRunner@{tensorflow::serving::TensorFlowMultiInferenceRunner}}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classtensorflow_1_1serving_1_1TensorFlowMultiInferenceRunner_af6dc0a8024a45ea4705403a0e9c45edc}\label{classtensorflow_1_1serving_1_1TensorFlowMultiInferenceRunner_af6dc0a8024a45ea4705403a0e9c45edc}} 
{\bfseries Tensor\+Flow\+Multi\+Inference\+Runner} (Session $\ast$session, const Meta\+Graph\+Def $\ast$meta\+\_\+graph\+\_\+def)
\item 
\mbox{\Hypertarget{classtensorflow_1_1serving_1_1TensorFlowMultiInferenceRunner_a8a39e31cd3012405ebc38a714ec35ce7}\label{classtensorflow_1_1serving_1_1TensorFlowMultiInferenceRunner_a8a39e31cd3012405ebc38a714ec35ce7}} 
{\bfseries Tensor\+Flow\+Multi\+Inference\+Runner} (Session $\ast$session, const Meta\+Graph\+Def $\ast$meta\+\_\+graph\+\_\+def, absl\+::optional$<$ int64\+\_\+t $>$ servable\+\_\+version, const thread\+::\+Thread\+Pool\+Options \&thread\+\_\+pool\+\_\+options=thread\+::\+Thread\+Pool\+Options())
\item 
\mbox{\Hypertarget{classtensorflow_1_1serving_1_1TensorFlowMultiInferenceRunner_acd77005f53ee1ad2575f08abdd52eff0}\label{classtensorflow_1_1serving_1_1TensorFlowMultiInferenceRunner_acd77005f53ee1ad2575f08abdd52eff0}} 
Status {\bfseries Infer} (const Run\+Options \&run\+\_\+options, const Multi\+Inference\+Request \&request, Multi\+Inference\+Response $\ast$response)
\end{DoxyCompactItemize}


The documentation for this class was generated from the following files\+:\begin{DoxyCompactItemize}
\item 
tensorflow\+\_\+serving/servables/tensorflow/multi\+\_\+inference.\+h\item 
tensorflow\+\_\+serving/servables/tensorflow/multi\+\_\+inference.\+cc\end{DoxyCompactItemize}
